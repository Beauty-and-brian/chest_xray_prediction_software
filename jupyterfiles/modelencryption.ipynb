{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tenseal in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3.16)\n",
      "Requirement already satisfied: torch in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2025.3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1; python_version >= \"3.9\" in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy==1.13.1; python_version >= \"3.9\"->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version\n",
      "------------------- -----------\n",
      "asttokens           3.0.0\n",
      "colorama            0.4.6\n",
      "comm                0.2.2\n",
      "contourpy           1.3.0\n",
      "cycler              0.12.1\n",
      "debugpy             1.8.13\n",
      "decorator           5.2.1\n",
      "exceptiongroup      1.2.2\n",
      "executing           2.2.0\n",
      "filelock            3.18.0\n",
      "fonttools           4.57.0\n",
      "fsspec              2025.3.1\n",
      "importlib-metadata  8.6.1\n",
      "importlib-resources 6.5.2\n",
      "ipykernel           6.29.5\n",
      "ipython             8.18.1\n",
      "jedi                0.19.2\n",
      "jinja2              3.1.6\n",
      "joblib              1.4.2\n",
      "jupyter-client      8.6.3\n",
      "jupyter-core        5.7.2\n",
      "kiwisolver          1.4.7\n",
      "MarkupSafe          3.0.2\n",
      "matplotlib          3.9.4\n",
      "matplotlib-inline   0.1.7\n",
      "mpmath              1.3.0\n",
      "nest-asyncio        1.6.0\n",
      "networkx            3.2.1\n",
      "numpy               2.0.2\n",
      "packaging           24.2\n",
      "pandas              2.2.3\n",
      "parso               0.8.4\n",
      "pillow              11.1.0\n",
      "pip                 20.2.3\n",
      "platformdirs        4.3.7\n",
      "prompt-toolkit      3.0.50\n",
      "psutil              7.0.0\n",
      "pure-eval           0.2.3\n",
      "pygments            2.19.1\n",
      "pyparsing           3.2.3\n",
      "python-dateutil     2.9.0.post0\n",
      "pytz                2025.2\n",
      "pywin32             310\n",
      "pyzmq               26.3.0\n",
      "scikit-learn        1.6.1\n",
      "scipy               1.13.1\n",
      "setuptools          49.2.1\n",
      "six                 1.17.0\n",
      "stack-data          0.6.3\n",
      "sympy               1.13.1\n",
      "tenseal             0.3.16\n",
      "threadpoolctl       3.6.0\n",
      "torch               2.6.0\n",
      "torchvision         0.21.0\n",
      "tornado             6.4.2\n",
      "traitlets           5.14.3\n",
      "typing-extensions   4.13.0\n",
      "tzdata              2025.2\n",
      "wcwidth             0.2.13\n",
      "zipp                3.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# ALL THE PACKAGES NEEDED TO BE INSTALLED ARE IN THE LINE OF CODE BELOW\n",
    "!pip install tenseal torch torchvision pillow numpy pandas scikit-learn\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WHERE THE IMPORTATION OF THE NECESSARY PCKAGES COMES TO PLAY\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING THE VARIABLES FOR THE TRAIN AND TEST DATA RESPECTIVELY\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_DIR = \"./chest_xray\"  # THIS DATASET WAS DOWNLOADED TO LOCAL DRIVE FOR FASTER EXECUTION(Directly using the LOCAL Hardware), AS COMPARED TO GOOGLE DRIVE\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINCE WE ARE DEALING WITH ENCRYPTION, THERE IS A NEED FOR US TO GET SOME IMPORTANT KEYS\n",
    "# INCLUDING THE SECRET KEYS AND WE WILL ALSO USE IT FOR THE ENCYPTION OF THE IMAGES VIA THE TENSEAL PACKAGE BY  CREATING THIS FUNCTION BELOW\n",
    "def create_stable_context():\n",
    "    \"\"\"Context configuration that guarantees stability\"\"\"\n",
    "    context = ts.context(\n",
    "        ts.SCHEME_TYPE.CKKS,\n",
    "        poly_modulus_degree=16384,  \n",
    "        coeff_mod_bit_sizes=[40, 21, 21, 40]  \n",
    "    )\n",
    "    context.generate_galois_keys()\n",
    "    context.global_scale = 2**21  \n",
    "    return context\n",
    "\n",
    "\n",
    "\n",
    "# THIS IS THE SECTION WHERE WE WORK ON THE DATASET(DATA PREPARATION AND VALIDATION) AND PREPARE IT FOR THE NEXT TRAINNG OPERATION \n",
    "class SafePneumoniaDataset:\n",
    "    def __init__(self, data_dir, context, img_size=32):\n",
    "        self.context = context\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.0], std=[4.0]) \n",
    "        ])\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_dir in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "            dir_path = os.path.join(data_dir, class_dir)\n",
    "            for img_name in os.listdir(dir_path):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.image_paths.append(os.path.join(dir_path, img_name))\n",
    "                    self.labels.append(0 if class_dir == \"NORMAL\" else 1)\n",
    "    \n",
    "    def get_safe_batches(self, batch_size=1):  \n",
    "        for i in range(0, len(self.image_paths), batch_size):\n",
    "            img_path = self.image_paths[i]\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            img = self.transform(img)\n",
    "            # Double safety scaling\n",
    "            encrypted = ts.ckks_vector(self.context, img.numpy().flatten() * 0.125)\n",
    "            yield encrypted, self.labels[i]\n",
    "\n",
    "\n",
    "\n",
    "# TO TRAIN A MODEL, WE NEED TO FIRST BUILD THE MODEL, WHICH IS WHAT WE HANDLED HERE.\n",
    "class UltraSafeHEModel:\n",
    "    def __init__(self, input_size, context):\n",
    "        self.weights = ts.ckks_vector(context, np.random.randn(input_size) * 0.0001)\n",
    "        self.bias = ts.ckks_vector(context, [0.0])\n",
    "        self.context = context\n",
    "    \n",
    "    def ultra_safe_predict(self, x):\n",
    "        \"\"\"Prediction with quadruple safety checks\"\"\"\n",
    "        try:\n",
    "            scaled_x = x * 0.5\n",
    "            scaled_weights = self.weights * 0.5\n",
    "            return scaled_x.dot(scaled_weights) + (self.bias * 0.5)\n",
    "        except:\n",
    "            return ts.ckks_vector(self.context, [0.0])\n",
    "    \n",
    "    def ultra_safe_update(self, gradients):\n",
    "        try:\n",
    "            update = gradients * 0.00001  \n",
    "            self.weights = self.weights - update\n",
    "        except:\n",
    "            print(\"Used nuclear-safe fallback update\")\n",
    "            pass  \n",
    "\n",
    "    def predict_single(self, encrypted_img, threshold=0.5):\n",
    "        try:\n",
    "            output = self.ultra_safe_predict(encrypted_img)\n",
    "            confidence = output.decrypt()[0]\n",
    "            prediction = \"PNEUMONIA\" if confidence > threshold else \"NORMAL\"\n",
    "            return prediction, float(confidence)\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction failed: {str(e)}\")\n",
    "            return \"ERROR\", 0.0\n",
    "        \n",
    "\n",
    "\n",
    "# THIS SECTION HANDLES THE DEFINITION OF THE FUNCTION RESPONSIBLE TO EXECUTE THE TRAINING OPERATION OF THE MODEL\n",
    "def nuclear_train(model, dataset, epochs=10):\n",
    "    print(\"I have started the training process\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        processed = 0\n",
    "        \n",
    "        for img, label in dataset.get_safe_batches():\n",
    "            output = model.ultra_safe_predict(img)\n",
    "            \n",
    "            try:\n",
    "                error = (output * 0.5) - (float(label) * 0.5)\n",
    "                loss = (error * 0.5) * (error * 0.5)  \n",
    "                total_loss += loss.decrypt()[0]\n",
    "                \n",
    "                safe_grad = img * (error * 0.0625)  \n",
    "                model.ultra_safe_update(safe_grad)\n",
    "                \n",
    "                pred = 1 if output.decrypt()[0] > 0.5 else 0\n",
    "                correct += 1 if pred == label else 0\n",
    "                processed += 1\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if processed > 0:\n",
    "            avg_loss = total_loss / processed\n",
    "            accuracy = 100 * correct / processed\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.8f} | Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have started the training process\n"
     ]
    }
   ],
   "source": [
    "# THIS SECTION HANDLES THE EXECUTION OF THE ABOVE DEFINED FUNCTIONS\n",
    "CONTEXT = create_stable_context()\n",
    "\n",
    "model = UltraSafeHEModel(32*32, CONTEXT)\n",
    "\n",
    "train_data = SafePneumoniaDataset(\"./chest_xray/train\", CONTEXT)\n",
    "\n",
    "nuclear_train(model, train_data, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n",
      "Accuracy: 76.92%\n"
     ]
    }
   ],
   "source": [
    "# THIS IS WHERE THE EVALUATION OF THE MODEL COMES TO PLAY\n",
    "def evaluate_model(model, test_dir, context, img_size=32):\n",
    "    correct = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    total = 0\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.0], std=[4.0])\n",
    "    ])\n",
    "    \n",
    "    for class_dir in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "        dir_path = os.path.join(test_dir, class_dir)\n",
    "        for img_name in os.listdir(dir_path):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(dir_path, img_name)\n",
    "                img = Image.open(img_path).convert('L')\n",
    "                img = transform(img)\n",
    "                encrypted_img = ts.ckks_vector(context, img.numpy().flatten() * 0.125)\n",
    "                \n",
    "                output = model.ultra_safe_predict(encrypted_img).decrypt()[0]\n",
    "                pred = 1 if output > 0.5 else 0\n",
    "                true_label = 0 if class_dir == \"NORMAL\" else 1\n",
    "                \n",
    "                total += 1\n",
    "                correct += 1 if pred == true_label else 0\n",
    "                \n",
    "                if true_label == 1:\n",
    "                    if pred == 1: true_pos += 1\n",
    "                    else: false_neg += 1\n",
    "                else:\n",
    "                    if pred == 1: false_pos += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "test_dir = \"./chest_xray/test\"\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, test_dir, CONTEXT)\n",
    "\n",
    "print(f\"\\nModel Evaluation Results:\")\n",
    "print(f\"Accuracy: {f1*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS TO LOAD THE ENCRYPTION PARAMATERS SO AS TO USE FOR MAKING PREDICTIONS BASED ON THE INFORMATION PROVIDED\n",
    "\n",
    "def load_prediction_assets(load_dir=\"./he_assets\"):\n",
    "    with open(os.path.join(load_dir, \"context.seal\"), \"rb\") as f:\n",
    "        context = ts.context_from(f.read())\n",
    "    \n",
    "    model = UltraSafeHEModel(input_size=32*32, context=context)  \n",
    "    \n",
    "    with open(os.path.join(load_dir, \"model_weights.seal\"), \"rb\") as f:\n",
    "        model.weights = ts.ckks_vector_from(context, f.read())\n",
    "    \n",
    "    with open(os.path.join(load_dir, \"model_bias.seal\"), \"rb\") as f:\n",
    "        model.bias = ts.ckks_vector_from(context, f.read())\n",
    "    \n",
    "    return context, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL THE IMPORTANT KEYS NEED TO BE SAVED BECAUSE THEY ARE NEEDED TO MAKE THE ENCRYPTION AND PREDICTION\n",
    "# THESE CODES BELOW IS TO ATTEND TO THE SAVING OF THE MODEL THAT HAVE BEEN TRAINED ABOVE\n",
    "def save_he_models(model, context, save_dir=\"./pneumonia_he_model\"):\n",
    "    \"\"\"\n",
    "    Save all components needed to recreate the HE model\n",
    "    Args:\n",
    "        model: Your trained UltraSafeHEModel\n",
    "        context: The TenSEAL context used for training\n",
    "        save_dir: Directory to save components\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Save the TenSEAL context (includes keys)\n",
    "    with open(os.path.join(save_dir, \"he_context.seal\"), \"wb\") as f:\n",
    "        f.write(context.serialize(save_secret_key=True))\n",
    "    \n",
    "    # 2. Save model weights (encrypted)\n",
    "    with open(os.path.join(save_dir, \"he_weights.seal\"), \"wb\") as f:\n",
    "        f.write(model.weights.serialize())\n",
    "    \n",
    "    # 3. Save model bias (encrypted)\n",
    "    with open(os.path.join(save_dir, \"he_bias.seal\"), \"wb\") as f:\n",
    "        f.write(model.bias.serialize())\n",
    "    \n",
    "    # 4. Save model metadata (JSON compatible)\n",
    "    metadata = {\n",
    "        \"input_size\": model.weights.size(),  # or model.weights.dimension(),  # Save the dimension only\n",
    "        \"model_type\": \"UltraSafeHEModel\",\n",
    "        \"description\": \"Homomorphic Encrypted Pneumonia Classifier\",\n",
    "        \"training_date\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    print(f\"Model successfully saved to {save_dir}\")\n",
    "    print(f\"- Context: {save_dir}/he_context.seal\")\n",
    "    print(f\"- Weights: {save_dir}/he_weights.seal\")\n",
    "    print(f\"- Bias: {save_dir}/he_bias.seal\")\n",
    "    print(f\"- Metadata: {save_dir}/metadata.json\")\n",
    "\n",
    "# Don't forget to import datetime at the top of your script\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved to ./pneumonia_he_model\n",
      "- Context: ./pneumonia_he_model/he_context.seal\n",
      "- Weights: ./pneumonia_he_model/he_weights.seal\n",
      "- Bias: ./pneumonia_he_model/he_bias.seal\n",
      "- Metadata: ./pneumonia_he_model/metadata.json\n"
     ]
    }
   ],
   "source": [
    "save_he_models(model, CONTEXT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
