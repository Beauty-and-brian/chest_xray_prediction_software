{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL THE PACKAGES NEEDED TO BE INSTALLED ARE IN THE LINE OF CODE BELOW\n",
    "!pip install tenseal torch torchvision pillow numpy pandas scikit-learn\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ada51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WHERE THE IMPORTATION OF THE NECESSARY PCKAGES COMES TO PLAY\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tenseal as ts\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING THE VARIABLES FOR THE TRAIN AND TEST DATA RESPECTIVELY\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_DIR = \"./chest_xray\"  # THIS DATASET WAS DOWNLOADED TO LOCAL DRIVE FOR FASTER EXECUTION(Directly using the LOCAL Hardware), AS COMPARED TO GOOGLE DRIVE\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINCE WE ARE DEALING WITH ENCRYPTION, THERE IS A NEED FOR US TO GET SOME IMPORTANT KEYS\n",
    "# INCLUDING THE SECRET KEYS AND WE WILL ALSO USE IT FOR THE ENCYPTION OF THE IMAGES VIA THE TENSEAL PACKAGE BY  CREATING THIS FUNCTION BELOW\n",
    "def create_stable_context():\n",
    "    \"\"\"Context configuration that guarantees stability\"\"\"\n",
    "    context = ts.context(\n",
    "        ts.SCHEME_TYPE.CKKS,\n",
    "        poly_modulus_degree=16384,  \n",
    "        coeff_mod_bit_sizes= [60, 40, 40, 40, 60]\n",
    "        # coeff_mod_bit_sizes= [60, 40, 40, 60]\n",
    "        # coeff_mod_bit_sizes=[40, 21, 21, 40]  \n",
    "    )\n",
    "    context.generate_galois_keys()\n",
    "    context.global_scale = 2**21  \n",
    "    return context\n",
    "\n",
    "\n",
    "\n",
    "# THIS IS THE SECTION WHERE WE WORK ON THE DATASET(DATA PREPARATION AND VALIDATION) AND PREPARE IT FOR THE NEXT TRAINNG OPERATION \n",
    "class SafePneumoniaDataset:\n",
    "    def __init__(self, data_dir, context, img_size=64):\n",
    "        self.context = context\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.0], std=[4.0]) \n",
    "        ])\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_dir in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "            dir_path = os.path.join(data_dir, class_dir)\n",
    "            for img_name in os.listdir(dir_path):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.image_paths.append(os.path.join(dir_path, img_name))\n",
    "                    self.labels.append(0 if class_dir == \"NORMAL\" else 1)\n",
    "    \n",
    "    def get_safe_batches(self, batch_size=1):  \n",
    "        for i in range(0, len(self.image_paths), batch_size):\n",
    "            img_path = self.image_paths[i]\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            img = self.transform(img)\n",
    "            # Double safety scaling\n",
    "            encrypted = ts.ckks_vector(self.context, img.numpy().flatten() * 0.125)\n",
    "            yield encrypted, self.labels[i]\n",
    "\n",
    "\n",
    "# creating the Polynomial Activation Function\n",
    "class PolynomialActivation:\n",
    "    def __init__(self, a=0.25, b=0.5, c=0.0):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "\n",
    "    def __call__(self, enc_vector):\n",
    "        x = enc_vector\n",
    "        x_sq = x * x\n",
    "        return (x_sq * self.a) + (x * self.b) + self.c\n",
    "\n",
    "\n",
    "\n",
    "# TO TRAIN A MODEL, WE NEED TO FIRST BUILD THE MODEL, WHICH IS WHAT WE HANDLED HERE.\n",
    "class UltraSafeHEModel:\n",
    "    def __init__(self, input_size, context):\n",
    "        self.context = context\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        self.activation = PolynomialActivation(a=0.125, b=0.5, c=0.25)  # Non-linear activation\n",
    "\n",
    "    def ultra_safe_predict(self, encrypted_input):\n",
    "        linear_result = encrypted_input.dot(self.weights) + self.bias\n",
    "        return self.activation(linear_result)\n",
    "    \n",
    "    def ultra_safe_update(self, gradients):\n",
    "        try:\n",
    "            update = gradients * 0.00001  \n",
    "            self.weights = self.weights - update\n",
    "        except:\n",
    "            print(\"Used nuclear-safe fallback update\")\n",
    "            pass  \n",
    "\n",
    "    def predict_single(self, encrypted_img, threshold=0.5):\n",
    "        try:\n",
    "            output = self.ultra_safe_predict(encrypted_img)\n",
    "            confidence = output.decrypt()[0]\n",
    "            prediction = \"PNEUMONIA\" if confidence > threshold else \"NORMAL\"\n",
    "            return prediction, float(confidence)\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction failed: {str(e)}\")\n",
    "            return \"ERROR\", 0.0\n",
    "        \n",
    "\n",
    "\n",
    "# THIS SECTION HANDLES THE DEFINITION OF THE FUNCTION RESPONSIBLE TO EXECUTE THE TRAINING OPERATION OF THE MODEL\n",
    "def nuclear_train(model, dataset, epochs=10):\n",
    "    print(\"I have started the training process\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        processed = 0\n",
    "        \n",
    "        for img, label in dataset.get_safe_batches():\n",
    "            output = model.ultra_safe_predict(img)\n",
    "            \n",
    "            try:\n",
    "                error = (output * 0.5) - (float(label) * 0.5)\n",
    "                loss = (error * 0.5) * (error * 0.5)  \n",
    "                total_loss += loss.decrypt()[0]\n",
    "                \n",
    "                safe_grad = img * (error * 0.0625)  \n",
    "                model.ultra_safe_update(safe_grad)\n",
    "                \n",
    "                pred = 1 if output.decrypt()[0] > 0.5 else 0\n",
    "                correct += 1 if pred == label else 0\n",
    "                processed += 1\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if processed > 0:\n",
    "            avg_loss = total_loss / processed\n",
    "            accuracy = 100 * correct / processed\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.8f} | Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SECTION HANDLES THE EXECUTION OF THE ABOVE DEFINED FUNCTIONS\n",
    "CONTEXT = create_stable_context()\n",
    "\n",
    "model = UltraSafeHEModel(64*64, CONTEXT)\n",
    "\n",
    "train_data = SafePneumoniaDataset(\"./chest_xray/train\", CONTEXT)\n",
    "\n",
    "nuclear_train(model, train_data, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cdd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WHERE THE EVALUATION OF THE MODEL COMES TO PLAY\n",
    "def evaluate_model(model, test_dir, context, img_size=32):\n",
    "    correct = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    total = 0\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.0], std=[4.0])\n",
    "    ])\n",
    "    \n",
    "    for class_dir in [\"NORMAL\", \"PNEUMONIA\"]:\n",
    "        dir_path = os.path.join(test_dir, class_dir)\n",
    "        for img_name in os.listdir(dir_path):\n",
    "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                img_path = os.path.join(dir_path, img_name)\n",
    "                img = Image.open(img_path).convert('L')\n",
    "                img = transform(img)\n",
    "                encrypted_img = ts.ckks_vector(context, img.numpy().flatten() * 0.125)\n",
    "                \n",
    "                output = model.ultra_safe_predict(encrypted_img).decrypt()[0]\n",
    "                pred = 1 if output > 0.5 else 0\n",
    "                true_label = 0 if class_dir == \"NORMAL\" else 1\n",
    "                \n",
    "                total += 1\n",
    "                correct += 1 if pred == true_label else 0\n",
    "                \n",
    "                if true_label == 1:\n",
    "                    if pred == 1: true_pos += 1\n",
    "                    else: false_neg += 1\n",
    "                else:\n",
    "                    if pred == 1: false_pos += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "    recall = true_pos / (true_pos + false_neg) if (true_pos + false_neg) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "test_dir = \"./chest_xray/test\"\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, test_dir, CONTEXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46305e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL THE IMPORTANT KEYS NEED TO BE SAVED BECAUSE THEY ARE NEEDED TO MAKE THE ENCRYPTION AND PREDICTION\n",
    "# THESE CODES BELOW IS TO ATTEND TO THE SAVING OF THE MODEL THAT HAVE BEEN TRAINED ABOVE\n",
    "def save_he_models(model, context, save_dir=\"./pneumonia_he_model\"):\n",
    "    \"\"\"\n",
    "    Save all components needed to recreate the HE model\n",
    "    Args:\n",
    "        model: Your trained UltraSafeHEModel\n",
    "        context: The TenSEAL context used for training\n",
    "        save_dir: Directory to save components\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Save the TenSEAL context (includes keys)\n",
    "    with open(os.path.join(save_dir, \"he_context.seal\"), \"wb\") as f:\n",
    "        f.write(context.serialize(save_secret_key=True))\n",
    "    \n",
    "    # 2. Save model weights (encrypted)\n",
    "    with open(os.path.join(save_dir, \"he_weights.seal\"), \"wb\") as f:\n",
    "        f.write(model.weights.serialize())\n",
    "    \n",
    "    # 3. Save model bias (encrypted)\n",
    "    with open(os.path.join(save_dir, \"he_bias.seal\"), \"wb\") as f:\n",
    "        f.write(model.bias.serialize())\n",
    "    \n",
    "    # 4. Save model metadata (JSON compatible)\n",
    "    metadata = {\n",
    "        \"input_size\": model.weights.size(),  # or model.weights.dimension(),  # Save the dimension only\n",
    "        \"model_type\": \"UltraSafeHEModel\",\n",
    "        \"description\": \"Homomorphic Encrypted Pneumonia Classifier\",\n",
    "        \"training_date\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    with open(os.path.join(save_dir, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "    \n",
    "    print(f\"Model successfully saved to {save_dir}\")\n",
    "    print(f\"- Context: {save_dir}/he_context.seal\")\n",
    "    print(f\"- Weights: {save_dir}/he_weights.seal\")\n",
    "    print(f\"- Bias: {save_dir}/he_bias.seal\")\n",
    "    print(f\"- Metadata: {save_dir}/metadata.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_he_models(model, CONTEXT)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
