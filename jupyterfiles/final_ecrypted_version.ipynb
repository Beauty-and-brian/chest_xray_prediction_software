{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6064d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tenseal\n",
      "Version: 0.3.16\n",
      "Summary: A Library for Homomorphic Encryption Operations on Tensors\n",
      "Home-page: https://github.com/OpenMined/TenSEAL\n",
      "Author: OpenMined\n",
      "Author-email: info@openmined.org\n",
      "License: Apache-2.0\n",
      "Location: c:\\Developments\\Backend\\Python\\test offline jupyter\\venv\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_quantized_weights(file_path, scale=2**20):\n",
    "    weights = np.fromfile(file_path, dtype=np.float32)\n",
    "\n",
    "    quantized_weights = np.round(weights * scale).astype(np.int64)\n",
    "    return quantized_weights\n",
    "\n",
    "scale = 2**40\n",
    "conv1_weights = load_quantized_weights(\"./chest_xray/trainable_weights/conv1_weights.bin\", scale)\n",
    "conv2_weights = load_quantized_weights(\"./chest_xray/trainable_weights/conv2_weights.bin\", scale)\n",
    "conv3_weights = load_quantized_weights(\"./chest_xray/trainable_weights/conv3_weights.bin\", scale)\n",
    "dense_weights = load_quantized_weights(\"./chest_xray/trainable_weights/dense_weights.bin\", scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbc3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TenSEAL context have been created.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tenseal as ts\n",
    "\n",
    "# This is the Setup for TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=32768,\n",
    "    coeff_mod_bit_sizes=[60, 40, 40, 40, 40, 60]\n",
    ")\n",
    "\n",
    "# We are Setting global scale\n",
    "context.global_scale = scale\n",
    "\n",
    "# Let us Generate keys\n",
    "context.generate_galois_keys()\n",
    "\n",
    "print(\"TenSEAL context have been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50450d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_and_encrypt_batched(image_path, ctx, scale=2**20, slot_count=16384):\n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('RGB').resize((150, 150))\n",
    "    img_array = np.array(img).astype(np.float32) / 255.0\n",
    "    flat_input = img_array.flatten()\n",
    "\n",
    "    # Quantize to fixed-point integers\n",
    "    quantized = np.round(flat_input * scale).astype(np.int64)\n",
    "\n",
    "    # Split input into batches based on slot count\n",
    "    batches = [quantized[i:i + slot_count] for i in range(0, len(quantized), slot_count)]\n",
    "\n",
    "    # Encrypt each batch\n",
    "    encrypted_batches = [ts.ckks_vector(ctx, batch) for batch in batches]\n",
    "\n",
    "    return encrypted_batches, img_array.shape\n",
    "\n",
    "# Example usage\n",
    "encrypted_input, input_shape = preprocess_and_encrypt_batched(\"./chest_xray/test/NORMAL/IM-0001-0001.jpeg\", context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa24a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tenseal as ts\n",
    "\n",
    "def fhe_conv2d_simulated(batch, kernel, kernel_size=3, channels=3):\n",
    "    # 1. Get info about encrypted vector\n",
    "    batch_size = batch.size()\n",
    "    window_size = kernel_size * kernel_size * channels  # e.g., 3x3x3 = 27\n",
    "\n",
    "    # 2. Ensure kernel is a flat numpy array\n",
    "    if isinstance(kernel, list):\n",
    "        kernel = np.array(kernel)  # Convert list to numpy array if needed\n",
    "    kernel_flat = kernel.flatten()[:window_size]  # Take only first 27 elements\n",
    "\n",
    "    # 3. Create padded kernel to match batch size\n",
    "    kernel_padded = np.zeros(batch_size)\n",
    "    kernel_padded[:window_size] = kernel_flat  # Now this should work\n",
    "\n",
    "    # 4. Convert to plaintext tensor\n",
    "    kernel_pt = ts.plain_tensor(kernel_padded)\n",
    "\n",
    "    # 5. Apply dot product with encrypted input\n",
    "    result = batch.dot(kernel_pt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d88e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhe_conv2d(batches, weights, kernel_size=3, in_channels=3, out_channels=32):\n",
    "    results = []\n",
    "    for batch in batches:\n",
    "        res = fhe_conv2d_simulated(batch, weights, kernel_size, in_channels)\n",
    "        results.append(res)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf63e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhe_relu(x_list):\n",
    "    results = []\n",
    "    for vec in x_list:\n",
    "        squared = vec.mul(vec)\n",
    "        results.append(squared)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47378941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhe_max_pooling(x_list):\n",
    "    \"\"\"Approximates max pooling using average\"\"\"\n",
    "    return [vec.sum().mul(1.0 / vec.size()) for vec in x_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb698baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhe_dense_layer(x_batches, weights):\n",
    "    result = []\n",
    "    for batch in x_batches:\n",
    "        print(batch.size())\n",
    "        w_plain = ts.plain_tensor(weights[:batch.size()])\n",
    "        result.append(batch.dot(w_plain))\n",
    "    return ts.ckks_vector_sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f120a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypted_predict_batched(encrypted_batches):\n",
    "    # Only ONE Conv + ReLU + MaxPooling\n",
    "    x = fhe_conv2d(encrypted_batches, conv1_weights)\n",
    "    x = fhe_relu(x)\n",
    "    x = fhe_max_pooling(x)\n",
    "\n",
    "    # Flatten and combine results before dense layer\n",
    "    if len(x) == 0:\n",
    "        raise ValueError(\"No values after max pooling\")\n",
    "\n",
    "    x_combined = sum(x[1:], x[0])  # Combine pooled outputs\n",
    "\n",
    "    # Truncate or pad input to match dense layer size\n",
    "    desired_size = dense_weights.shape[0]\n",
    "    actual_size = x_combined.size()\n",
    "\n",
    "    if desired_size > actual_size:\n",
    "        # Pad with zeros\n",
    "        padding = np.zeros(desired_size)\n",
    "        padding[:actual_size] = x_combined.decrypt()\n",
    "        padded_input = ts.ckks_vector(x_combined.context(), padding)\n",
    "        masked_input = padded_input\n",
    "    else:\n",
    "        # Truncate input\n",
    "        mask = np.zeros(actual_size)\n",
    "        mask[:desired_size] = 1.0\n",
    "        mask_pt = ts.plain_tensor(mask)\n",
    "        masked_input = x_combined.mul(mask_pt)\n",
    "\n",
    "    # Now do dot product\n",
    "    output = masked_input.dot(ts.plain_tensor(dense_weights))\n",
    "    return output\n",
    "\n",
    "\n",
    "# Run prediction\n",
    "encrypted_output = encrypted_predict_batched(encrypted_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fac65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "encrypted_output = encrypted_predict_batched(encrypted_input)\n",
    "\n",
    "# Step 1: Decrypt\n",
    "decrypted_output = encrypted_output.decrypt()\n",
    "\n",
    "# Step 2: Rescale\n",
    "predicted_logit = decrypted_output[0] / (1 << 20)\n",
    "\n",
    "# Step 3: Apply sigmoid\n",
    "import math\n",
    "sigmoid = lambda x: 1 / (1 + math.exp(-x))\n",
    "predicted_prob = sigmoid(predicted_logit)\n",
    "\n",
    "# Step 4: Print result\n",
    "print(f\"Predicted logit: {predicted_logit}\")\n",
    "print(f\"Pneumonia probability: {predicted_prob:.4f}\")\n",
    "\n",
    "# Step 5: Make a prediction\n",
    "if predicted_prob > 0.5:\n",
    "    print(\"Prediction: Pneumonia detected\")\n",
    "else:\n",
    "    print(\"Prediction: No pneumonia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c7ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
